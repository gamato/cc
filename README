CC
==

CC is ZMQ proxy for specific type of ZMQ messages (CC messages).

It listens on single ZMQ socket, and processes messages
by matching message type to handler.

It also has optional support for launching daemon processes
and providing config to them.  It is provided only for easier
administration, as any daemon can be written to be standalone.


CC message
----------

First quick intro to ZMQ messages:  ZMQ transports blobs,
with header that specifies length for the blob and whether
it is last blob or not.  So one logical message can contain
one or more blobs.  ZMQ calls it "multipart message".

Simple ZMQ request-reply pattern, implemented by zmq.REP, zmq.XREP
sockets, is to add additional blob at the start of the message
on each hop, which contains socket id from where the message
came from.  So on reply the message can be routed by over several
hops, each one removes the socket id when it send it further.

Empty part ('') separates such socket ids from actual body parts.

CC messages uses such routing, additionally it specifies meaning
to following body parts:

0 - message type (eg. 'pub.infofile')
1 - body (json)
2 - signature

The message type is contained also in json, it is separated
out to make routing easier.

Message types
-------------

Message type contains dot-separated multiple ids.
So routing pattern can be applied to full id or only
some prefix parts.

Eg. id 'pub.infofile' can be routed either full
pattern or simply 'pub', which will route all 'pub'
messages to some handler.

- pub.infofile, pub.state, pub.stats
- log.info, log.error, ...
- job.*
- req.* ??


CC handlers
-----------

Handler is a Python class that is registered for a message type pattern.

Examples:

cc.handler.proxy: sends message to another CC instance
cc.handler.database: launches db function with message
cc.handler.taskrouter: keeps track of routes to task executors
cc.handler.infowriter: writes infofiles
cc.handler.locallogger: writes logfiles
cc.handler.jobmgr: local jobs [daemons / tasks] query it for config and keepalive


CC daemons
----------

These are daemons that are launched and managed by CC.
They act as ordinary clients, except they are configured
from CC config, instead of separate standalone scripts.

Examples:

- cc.daemon.infosender: reads info files, sends them to CC
- cc.daemon.taskrunner: registers on taskrouter, waits for tasks
- cc.daemon.discovery: discovers things


Patterns
--------

Neither handlers nor daemons need to be tied/managed by CC,
they can always be launched as standalone services.
They are managed with CC only for easier administration.

That also means there are few daemon/handler combinations
that make sense, and others that don't.

To avoid accidental mis-configs, the handlers are checked
against ccserver's cc-role option.

cc-role = local
- listens on localhost
- handlers: jobmgr, proxy, locallogger
- daemons: taskexec, infosender, ...

cc-role = remote
- listens network
- handlers: proxy / dbservice / logwriter / infowriter
- daemons: -


Crypto
------

CC uses the CMS/PKCS7 message format (from SMIME) for signing
and encrypting.

Currently ccserver and daemons have crypto config, handlers
all share the top-level ccserver's one.  Daemon config
is inherited from master ccserver.

cms-keystore:
  directory where certs and private keys are stored.  Private
  keys are under ./private subdir.  So common server keystore
  would look like:

  ./server.crt
  ./ca.crt
  ./confdb.crt
  ./private/server.key

cms-sign:
  Key name to sign as.  Requires files ./$key.crt and ./private/$key.key
  under keystore.  If set, all outgoing messages are signed.

cms-verify-ca:
  Cert name to use to signature verification.  Requires
  ./$name.crt under keystore.  If set, incoming messages
  must be signed under key certified by CA.

cms-encrypt:
  Cert name to encrypt to.  Requires ./$name.crt under keystore.
  Note - this should not be CA cert but some service one, like 'infoserver'.
  Must be paired with cms-sign.

cms-decrypt:
  Key and cert name to decrypt as.  Requires $name.crt and ./private/$name.key.
  Note - service key.
  Must be paired with cms-verify-ca.


TODO
----

- jobmgr: track keepalive, relaunch if dead?
- ccjob: implement task logic (just job_name picking?)
- taskexec: implement

- api: refactor zmq script w/ ioloop out
- api: common zmq socket tuning
- api: rename 'req'.  (mtype, dest, type, target?)

task poller
-----------
- daemon that periodically check for new tasks from db (pgq / polling)
- sends task under 'task.send' message type to CC which has 'taskrouter'
  handler configured.

task executor
-------------
- cc daemon that sends 'task.register' msg to CC with 'taskrouter' handler. (done)
- when it receives task, must execute corresponding script.

crypto
------
- user/server name in cert must be checked for username in message
  - define place in cert to have user
  - define name field in message
  - server: check if cert matches msg
  - server: check if user is authorized to access service
    (unrelated to crypto, except when we put access rights into cert)
  - make cert details available to python code (done)
- replayability fix (may not matter for info & log msgs), but is needed
  for confdb access:
  - client: have unique id for each message
  - client: have timestamp in message (done)
  - server: keep track of msgids for last 5m, drop dup messages
  - server: check message timestamp, drop old messages
